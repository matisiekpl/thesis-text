\chapter{Realizacja projektu}


\section{Wykorzystane technologie}

\subsection{Język programowania Python}

Kod projektu został napisany w języku Python. Wybór tego języka był spowodowany szeroką dostępnością bibliotek i
narzędzi wspomagających uczenie maszynowe. W szczególności należy zwrócić uwagę na biblioteki \textit{PyTorch} (użyta w projekcie) oraz \textit{Tensorflow} (alternatywa).
Są to dwie najpopularniejsze biblioteki do operowania na tensorach (tensor to uogólnienie macierzy na wiele wymiarów).
Obie pozwalają na przyśpieszanie obliczeń z użyciem zewnętrznych akceleratorów takich jak np. karty graficzne.

Podczas prac badawczych, wykorzystana wersja Pythona to \textit{3.12.0}.

\subsection{Biblioteka PyTorch}

Biblioteka PyTorch jest obecnie najpopularniejszą biblioteką uczenia maszynowego.
Pozwala ona projektować obliczenia w formie modułów i posiada silnik automatycznego różniczkowania grafu obliczeniowego (z ang. \textit{autograd}).
Owy silnik jest kluczowy z perspektywy trenowania sieci neuronowych, ponieważ jest w stanie optymalizować parametry modelu.
Warto zwrócić uwagę na to, że PyTorch stawia nacisk na przejrzystość obliczeń - dla porównania operacje w Tensorflow są nierzadko
ukryte pod gotowymi funkcjami (zob. listing \ref{lst:tensorflow_sample} i \ref{lst:pytorch_sample})

\begin{lstlisting}[language=ipython,caption={Przykładowa sieć neuronowa w Tensorflow},label={lst:tensorflow_sample}]
tensorflow_model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

tensorflow_model.compile() # Brak doglebnej kontroli nad przeplywem obliczen
\end{lstlisting}


\begin{lstlisting}[language=ipython,caption={Przykładowa sieć neuronowa w PyTorch},label={lst:pytorch_sample}]
class PyTorchNetwork(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(28 * 28, 128)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x): # Dokladna kontrola nad przeplywem obliczen
        x = self.flatten(x)
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        return x
\end{lstlisting}

PyTorch oferuje również zestaw narzędzi do przetwarzania danych, dostarcza również gotowe, pretrenowane modele dla najpopularniejszych architektur.
Przykładami są pakiety \textit{torchvision} lub \textit{torch.utils}. Cała biblioteka jest w stanie wykorzystywać karty graficzne (z ang. \textit{graphical processing unit, GPU}) do przyspieszania obliczeń.

\subsection{Biblioteka OpenCV}

Biblioteka OpenCV \cite{opencv} dostarcza implementacje wielu konwencjonalnych algorytmów wizji komputerowej.
OpenCV eksponuje interfejs programistyczny, dzięki któremu programista Pythona może komunikować się z implementacją algorytmów w C++.
To zapewnia szybkość wykonywania obliczeń, jednocześnie nie wymuszając na programiście pisania kodu w C++. Przykład wykorzystania biblioteki OpenCV widoczny jest na listingu \ref{lst:opencv_sample}
- kod wylicza momenty Hu.

OpenCV w niniejszej pracy jest wykorzystywane do automatycznej ekstrakcji kwadratów z komórkami na podstawie dużego zdjęcia spod mikroskopu.
Więcej informacji na ten temat w rozdziale \ref{sec:automatyczny-licznik-limfoblastow}.

\begin{lstlisting}[language=ipython,caption={Obliczenie momentów Hu z użyciem OpenCV}, label={lst:opencv_sample}]
import cv2

image = cv2.imread('obraz.jpg', 0)  # 0 oznacza wczytanie obrazu w odcieniach szarosci

hu_moments = cv2.HuMoments(cv2.moments(image)).flatten()

print("Momenty Hu:")
for i in range(0, 7):
    print(f"Moment {i+1}: {hu_moments[i]}")
\end{lstlisting}

\subsection{Inne narzędzia}

Kod źródłowy projektu był przechowywany w repozytorium na platformie GitHub (dostępny pod adresem \url{https://github.com/matisiekpl/thesis}).
Wykresy były generowane za pomocą biblioteki \textit{matplotlib} \cite{matplotlib},
a metryki liczone z użyciem funkcji pakietu \textit{scikit-learn} \cite{scikit_learn}.

\subsection{Sprzęt}

Do prac badawczych został użyty Apple Macbook Pro 2020 (M1/16GB pamięci). Trenowanie sieci odbywało się na platformie \textit{kaggle.com}, która oferuje bezpłatne 30 godzin obliczeń co miesiąc z kartą graficzną \textit{NVIDIA P100}.


\section{Zbiór danych}

Wykorzystany w projekcie zbiór danych to kolekcja 170 tysięcy zdjęć komórek z rozmazów szpiku kostnego.
Zdjęcia mają nadane etykiety przez diagnostów i przedstawiają różne komórki widziane pod mikroskopem.
Próbki szpiku kostnego pochodzą z biopsji 945 pacjentów z Monachijskiego Labolatorium Białaczek (\textit{MLL Münchner Leukämielabor} \cite{mll}).
Akwizycja obrazu polegała na wykonaniu zdjęcia mikroskopią Brightfield'a z 40-krotnym powiększeniem.
Producentem mikroskopu było przedsiębiorstwo Fraunhofer IIS.

\begin{figure}
    \includegraphics[width=\textwidth]{images_count}
    \caption{Wizualizacja ilościowa rozkładu próbek w klasach w zbiorze danych}
    \label{fig:images_count_vis}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[height=0.9\textheight]{images_examples}
    \caption{Podgląd zdjęć komórek ze zbioru danych dla każdej z klas}
    \label{fig:images_examples}
\end{figure}

Komórki były barwione metodą Maya-Grünwalda-Giemsa \cite{histology}. Zbiór danych zawiera 21 klas.
Wizualizacja rozkładu klas jest widoczna na rys. \ref{fig:images_count_vis}.
Zbiór danych jest niezbalansowany, ponieważ ilość obrazów w każdej klasie mocno się różni.
Przykładowe zdjęcia są widoczne na rys \ref{fig:images_examples}.

%\begin{table}
%    \begin{center}
%        \caption{Klasy obrazów w zbiorze danych}
%        \label{tab:images_count}
%        \begin{tabular}{|l|l|l|}
%            \hline
%            Klasa & Nazwa & Liczba obrazów \\
%            \hline
%            NGS & Segmentowany neutrofil & 29001 \\
%            \hline
%            EBO & Erytroblast & 27396 \\
%            \hline
%            LYT & Limfocyt & 26242 \\
%            \hline
%            ART & Artefakt & 19630 \\
%            \hline
%            PMO & Promielocyt & 11994 \\
%            \hline
%            BLA & Blast & 11973 \\
%            \hline
%            NGB & Krwinka biała pałeczkowata & 9968 \\
%            \hline
%            PLM & Komórka plazmatyczna & 7630 \\
%            \hline
%            MYB & Mielocyt & 6558 \\
%            \hline
%            EOS & Eozynofil & 5883 \\
%            \hline
%            MON & Monocyte & 4040 \\
%            \hline
%            NIF & Brak rozpoznania & 3538 \\
%            \hline
%            MMZ & Metamielocyt & 3055 \\
%            \hline
%            PEB & Proerytroblast & 2740 \\
%            \hline
%            BAS & Bazofil & 441 \\
%            \hline
%            HAC & Włochata komórka & 409 \\
%            \hline
%            OTH & Inna komórka & 294 \\
%            \hline
%            LYI & Niedojrzały limfocyt & 65 \\
%            \hline
%            FGC & Fagocyt & 47 \\
%            \hline
%            KSC & Cienie komórkowe & 42 \\
%            \hline
%            ABE & Nieprawidłowy eozynofil & 8 \\
%            \hline
%        \end{tabular}
%    \end{center}
%\end{table}

%\begin{itemize}
%    \item Nieprawidłowy eozynofil
%    \item Artefakt
%    \item Bazofil
%    \item Blast
%    \item Erytroblast
%    \item Eozynofil
%    \item Fagocyt
%    \item Włochata komórka
%    \item Cienie komórkowe
%    \item Niedojrzały limfocyt
%    \item Metamielocyt
%    \item Krwinka biała pałeczkowata
%    \item Segmentowany neutrofil
%    \item Brak rozpoznania
%    \item Inna komórka
%    \item Proerytroblast
%    \item Komórka plazmatyczna
%    \item Promielocyt
%\end{itemize}


\section{Struktura projektu}

\subsection{Przygotowanie danych}

Zbiór danych to katalog ze zdjęciami. Zdjęcia są pogrupowane w podkatalogach, gdzie jego nazwa oznacza typ komórki.
Każdy podkatalog zawiera kolorowe zdjęcia w formacie \textit{.jpg} w rozmiarze \textit{250 pikseli x 250 pikseli}.
Przed treningiem sieci neuronowej konieczna jest przetwarzanie wstępne zbioru danych (z ang. \textit{preprocessing}).

\begin{lstlisting}[language=ipython,caption={Transformacja danych}, label={lst:transforms}]
transform = transforms.Compose([
    transforms.Resize((224, 224)), # przeskaluj obrazy
    transforms.RandomEqualize(1), # wyrownaj histogram z prawdopodobienstwem 1, czyli dla kazdego obrazu
    transforms.ToTensor(), # zamien na Tensor
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[
        0.229, 0.224, 0.225]), # normalizuj wedlug mediany i odch. stand.
])
\end{lstlisting}

Do realizacji przygotowania danych wykorzystano pakiet \textit{torchvision.transforms}.
Kod transformacji jest przedstawiony na listingu \ref{lst:transforms}.
Wykonuje on przeskalowanie obrazu wejściowego do rozmiaru \textit{224 piksele na 224 piksele}.
Następnie wyrównuje histogram i normalizuje według średniej i odchylenia standardowego.

Wyrównanie histogramu jest konieczne z powodu różnic w odcieniach barwienia Maya-Grünwalda-Giemsa.
Przy każdym wykonaniu rozmazu intensywność kolorów komórek jest inna.
Taka normalizacja zapobiega błędnemu nauczeniu się sieci neuronowej ze względu na odcień, a nie kształt i wygląd komórek.

Po przetwarzaniu, zbiór danych został podzielony na zestaw treningowy i walidacyjny w proporcjach odpowiednio \textit{80:20}.
Zestaw treningowy służy do optymalizacji parametrów sieci neuronowej.
Zestaw walidacyjny natomiast jest używany do sprawdzania jakości modelu na obrazach, których sieć neuronowa "nigdy nie widziała".

\subsection{Trening sieci neuronowej}

Niniejsza praca ma za zadanie między innymi porównać różne architektury splotowych sieci neuronowych i ocenić,
która z nich wypada najlepiej w zadaniu klasyfikacji komórek z rozmazów szpiku kostnego.
Omówiony poniżej trening sieci neuronowej o architekturze \textit{EfficientNet B0} wygląda tak samo dla innych architektur, takich jak \textit{EfficientNet B5}, \textit{ResNet} i innych.

Trenowanie sieci neuronowej z użyciem biblioteki PyTorch sprowadza się do iterowania po zbiorze wejściowym i wykonywania kroku optymalizacyjnego przy każdym przejściu.
Kod głównej funkcji treningowej jest widoczny na listingu \ref{lst:training}.

\begin{itemize}
    \item na listingu wykorzystano architekturę \textit{EfficientNet B0}
    \item jako funkcję straty użyto \textit{torch.nn.CrossEntropyLoss()}.
    Jest to funkcja używana do klasyfikatorów wieloklasowych.
    \item funkcja \textit{.to(device)} kopiuje tensory na urządzenie zewnętrzne, czyli kartę graficzną.
    Jest to wymagane, ponieważ model i dane muszą znajdować się w tym samym miejscu.
    Dzięki użyciu karty graficznej obliczenia są znacznie przyspieszone.
    \item \textit{optimizer.zero\_grad()} zeruje gradienty.
    Wywołanie tej funkcji jest konieczne z powodu domyślnego zachowania PyTorch, które akumuluje gradienty.
    Chcąc tego uniknąć, kod resetuje gradienty w grafie obliczeniowym przy każdej iteracji danych treningowych.
    \item \textit{loss.backward()} liczy gradienty w grafie obliczeniowym, zaś \textit{optimizer.step()} wykonuje krok optymalizacyjny.
\end{itemize}


%Poniżej opisano ważniejsze fragmenty kodu:
%\begin{itemize}
%    \item stworzenie obiektu ładującego dane (z ang. \textit{data loader}) - linijki 1 i 2.
%    \item stworzenie obiektu modelu - w tym przypadku architektury \textit{EfficientNet B0}. Patrz linijki 4-6.
%    \item określenie funkcji straty. W linijce 8 wykorzystano \textit{nn.CrossEntropyLoss()}, które służy do optymalizacji klasyfikatorów wieloklasowych.
%    \item wybór optymalizatora. Linijka 9 tworzy obiekt \textit{torch.optim.Adam}. Jest to optymalizator bazujący na gradiencie funkcji. W argumentach ustawiane jest tempo uczenia się (w tym przypadku przyjmuje wartość stałej \textit{LR}).
%    \item linijka 10 i 11 kopiuje model na urządzenie zewnętrzne - w tym przypadku kartę graficzną, która znacząco przyspiesza obliczenia.
%    \item \textit{model.train()} w linijce 21 ustawia model w trybie uczenia się. Jest to konieczne, ponieważ niektóre warstwy sieci neuronowej zachowują się inaczej podczas treningu i ewaluacji.
%    \item pętla \textit{for} w linijce 25 iteruje zbiór danych wejściowych, kopiując tensory na urządzenie zewnętrzne (model jak i dane muszą być w jednym miejscu).
%    \item \textit{optimizer.zero\_grad()} resetuje wszystkie gradienty w grafie obliczeniowym.
%    \item linijki 30-34 odpowiadają za wykonanie kroku optymalizacyjnego.
%\end{itemize}

\lstinputlisting[language=ipython,caption={Kod odpowiadający za trenowanie modelu \textit{EfficientNet B0}}, label={lst:training}]{train.py}
\lstinputlisting[language=ipython,caption={Kod odpowiadający ewaluację metryk}, label={lst:metrics}]{metrics.py}

\subsection{Ewaluacja jakości modelu}


\section{Interfejs użytkownika}


\section{Automatyczny licznik limfoblastów}\label{sec:automatyczny-licznik-limfoblastow}

